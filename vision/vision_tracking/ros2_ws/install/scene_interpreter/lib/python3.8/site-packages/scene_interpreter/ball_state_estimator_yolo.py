import cv2
from ultralytics import YOLO
from cv_bridge import CvBridge
from sensor_msgs.msg import Image
from .triangulation_utils import triangulate

def estimate_ball_3D_spatial_coords(model_path):
    # Initialize the YOLO model with the given path
    model = YOLO(model_path)
    bridge = CvBridge()
    publishers = []

    # Low-pass filter states and smoothing factor
    previous_3D_coords = None
    previous_2D_centers = [None] * 4
    alpha = 0.05  # Adjust this value for more or less smoothing (closer to 1 is less smoothing)

    def initialize_publishers(node, num_cameras):
        nonlocal publishers
        for i in range(num_cameras):
            publishers.append(node.create_publisher(Image, f"/camera_{i}/annotated_image", 10))

    def low_pass_filter(new_value, previous_value):
        if previous_value is None:
            return new_value
        return tuple(alpha * n + (1 - alpha) * p for n, p in zip(new_value, previous_value))


    def process_frame_with_yolo(frame, camera_label, publisher, camera_index):
        print(f"Processing frame from {camera_label} with YOLO...")
    
        # Use the YOLO model to detect objects in the frame
        results = model(frame, conf=0.06, iou=0.1, verbose=False)
    
        if not results or len(results) == 0 or results[0].boxes is None or len(results[0].boxes) == 0:
            print(f"No detections found in the frame from {camera_label}.")
            return frame, None

        # Annotate the frame with detections
        best_detection = max(results[0].boxes, key=lambda box: box.conf.cpu().item())
        x, y, w, h = best_detection.xywh.cpu()[0]
        cv2.rectangle(frame,
                      (int(x - w / 2), int(y - h / 2)),
                      (int(x + w / 2), int(y + h / 2)),
                      (0, 255, 0), 2)
        cv2.putText(frame,
                    f"Ball: ({x:.2f}, {y:.2f})",
                    (int(x - w / 2), int(y - h / 2) - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

        print(f"Detection - x: {x}, y: {y}")

        # Apply low-pass filter to the 2D detection
        nonlocal previous_2D_centers
        filtered_center = low_pass_filter((int(x), int(y)), previous_2D_centers[camera_index])
        previous_2D_centers[camera_index] = filtered_center

        # Publish the annotated frame to the corresponding topic
        publisher.publish(bridge.cv2_to_imgmsg(frame, encoding="bgr8"))

        return frame, filtered_center

    def helper(*frames, display_annotated, node):
        print("Starting helper function for triangulation...")
        if not publishers:
            initialize_publishers(node, len(frames))

        centers = []

        for i, frame in enumerate(frames):
            annotated_frame, center = process_frame_with_yolo(frame, f"Camera {i}", publishers[i], i)
            centers.append(center)

            # Show annotated frames only if user opts to display them
            if display_annotated:
                cv2.imshow(f"Annotated Frame - Camera {i}", annotated_frame)
        
        # Check that the ball has been detected by what cameras
        valid_centers = [center for center in centers if center is not None]

        # Say that at least 2 cameras need to have detected ball to work 
        if len(valid_centers) < 2:
            print("Triangulation failed: Not enough valid detections for triangulation.")
            return None, float('inf')

        print("Performing triangulation...")
        ball_spatial_coords, error = triangulate(centers)

        # Apply low-pass filter to the 3D spatial coordinates
        nonlocal previous_3D_coords
        if ball_spatial_coords is not None:
            ball_spatial_coords = low_pass_filter(ball_spatial_coords, previous_3D_coords)
            previous_3D_coords = ball_spatial_coords

        print("Triangulation result:", ball_spatial_coords, "Error:", error)
        return ball_spatial_coords, error

    return helper


# Initialize the triangulation helper function with the specified YOLO model path
estimate_ball_3D_spatial_coords = estimate_ball_3D_spatial_coords(
    model_path="/home/dvij/ee206-project/ping-pong-robot/ppr_ws/src/camera_feed/camera_feed/runs/detect/train4/weights/best.pt"
)
