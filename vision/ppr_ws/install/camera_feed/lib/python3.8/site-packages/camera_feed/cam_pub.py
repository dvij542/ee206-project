import rclpy # Python Client Library for ROS 2
from rclpy.node import Node # Handles the creation of nodes
from std_msgs.msg import Header
from sensor_msgs.msg import Image # Image is the message type
from cv_bridge import CvBridge # Package to convert between ROS and OpenCV Images
import cv2 # OpenCV library
import numpy as np
import time

from PIL import Image as PILImage
import cv2
import numpy as np

import gi
gi.require_version ('Aravis', '0.8')
from gi.repository import Aravis


def wait_until_next_start_point():
    # starts on the 5 second mark (1:00:00, 1:00:05, 1:00:10)
    start_point = 5 
    current_time = time.time()
    next_start_time = (current_time // start_point + 1) * start_point
    time.sleep(next_start_time - current_time)

class ImagePublisher(Node):
    def __init__(self):
        super().__init__(f'camera_publisher')

        self.declare_parameter('cam_num', 1)
        cam_num = self.get_parameter('cam_num').get_parameter_value().integer_value
        self.publisher_ = self.create_publisher(Image, f'cam_{cam_num}', 10)
        
        # Used to convert between ROS and OpenCV images
        self.br = CvBridge()

        EXPOSURE_TIME = 20000

        # map camera id to camera number
        cameras = {
            "Daheng Imaging-2BA200003814-FDN21120585": 1,
            "Daheng Imaging-2BA200003827-FDN21120598": 2,
            "Daheng Imaging-2BA200003813-FDN21120584": 3,
            "Daheng Imaging-2BA200003815-FDN21120586": 4,
        }

        # find the id corresponding to cam_num
        id = None
        for key, value in cameras.items():
            if value == cam_num:
                id = key
        assert id is not None
        self.get_logger().info('Found id')

        # set up camera object
        Aravis.enable_interface("Fake")
        cam = Aravis.Camera.new(id)
        # cam.set_pixel_format(Aravis.PIXEL_FORMAT_BAYER_RG_8)
        cam.set_string('AcquisitionFrameRateMode', 'On')
        cam.set_string('BalanceWhiteAuto', 'Continuous')
        cam.set_exposure_time(EXPOSURE_TIME)
        device = cam.get_device()
        device.set_string_feature_value("AcquisitionMode", "Continuous")
        payload = cam.get_payload()
        stream = cam.create_stream(None, None)
        for i in range(0,20):
            stream.push_buffer(Aravis.Buffer.new_allocate(payload))
        [_,_,width,height] = cam.get_region()

        wait_until_next_start_point()
        self.get_logger().info("Start acquisition")

        cam.start_acquisition()
        start_time = time.time()
        cam_num = cameras[id]
        # for i in tqdm(range(0,num_frames)):
        count = 0
        start = time.time()
        while True:          
            if count % 10 == 0:
                # self.get_logger().info(f'Camera {cam_num}: it took an average time of {(time.time() - start)/10} seconds to publish an image.')
                start = time.time()
                count = 0
            image = stream.pop_buffer()
            dataFromBuffer = image.get_data()
            image_pil = PILImage.frombytes('L',(width, height), dataFromBuffer)
            image_rgb = cv2.cvtColor(np.array(image_pil), cv2.COLOR_BAYER_RG2RGB) # GOTTA LOVE CHAT FUCKING GPT

            # cv2.imshow("Frame1", image_rgb)
            # cv2.waitKey(1)

            img = self.br.cv2_to_imgmsg(image_rgb)
            img.header = Header()
            img.header.stamp = self.get_clock().now().to_msg()
            self.publisher_.publish(img) 
            # self.get_logger().info('Publishing video frame')

            # plt.imsave(f"{folder}/camera_{cam_num}/image_{i:03d}.jpg", image_rgb)
            if image:
                stream.push_buffer(image)
        cam.stop_acquisition()

        self.get_logger().info("Stop acquisition")

        # wait_until_next_start_point()
        # print("Start acquisition")

        # num_frames = 500
        # folder = "src/camera_feed/snapshot/soft_hits"
        # counter = 0
        # while(counter < num_frames):
        #     print(os.getcwd())
        #     frame = cv2.imread(f"{folder}/camera_{cam_num}/image_{counter:03}.jpg")
        #     print(type(frame))
        #     print(frame.shape)
        #     img = self.br.cv2_to_imgmsg(frame)
        #     img.header = Header()
        #     img.header.stamp = self.get_clock().now().to_msg()
        #     self.publisher_.publish(img) 
        #     self.get_logger().info('Publishing video frame')
        #     counter += 1
        #     counter = counter % 500


        # while True:

        #     frame = np.zeros((1440, 1080, 3), dtype = np.uint8)

        #     # The 'cv2_to_imgmsg' method converts an OpenCV image to a ROS 2 image message
        #     self.publisher_.publish(self.br.cv2_to_imgmsg(frame)) 
        #     self.get_logger().info('Publishing video frame')


  
def main(args=None):
    # Initialize the rclpy library
    rclpy.init(args=args)
    image_publisher = ImagePublisher()
    rclpy.spin(image_publisher)
    image_publisher.destroy_node()
    rclpy.shutdown()
  
if __name__ == '__main__':
    main()
